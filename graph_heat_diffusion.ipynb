{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kvz0e6VVJTkP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6379ff75-b17a-4020-ff48-b41f80794471"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.5.3-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2023.6.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch_geometric) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.5.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dllBVMFuniXe",
        "outputId": "9c21c64e-04fc-4127-a6e1-10373ceee34e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.0+cu121\n"
          ]
        }
      ],
      "source": [
        "# Install required packages.\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "print(torch.__version__)\n",
        "\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-${TORCH}.html\n",
        "#!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def visualize_graph(G, color):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
        "                     node_color=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_embedding(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    h = h.detach().cpu().numpy()\n",
        "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "    if epoch is not None and loss is not None:\n",
        "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "import os.path as osp\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "from torch_geometric.utils import negative_sampling\n",
        "from torch_geometric.datasets import Planetoid\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import train_test_split_edges\n",
        "from torch_geometric.nn import BatchNorm, PNAConv, global_add_pool\n",
        "from torch_geometric.utils import degree"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the Data"
      ],
      "metadata": {
        "id": "5GMiBDnTosKl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0IUcJHrLUVh",
        "outputId": "f25fde71-ab4b-41fc-b797-c702228e5e53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/34.9 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.25.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.6\n",
            "Number of SMILES in QM9 dataset: 84780\n",
            "Example SMILES: N\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "import pandas as pd\n",
        "from rdkit import Chem\n",
        "\n",
        "def load_qm9_smiles(csv_file):\n",
        "    # Read the CSV file containing the QM9 dataset\n",
        "    df = pd.read_csv(csv_file)\n",
        "\n",
        "    # Extract SMILES strings\n",
        "    smiles_list = df['smiles'].tolist()\n",
        "\n",
        "    return smiles_list\n",
        "\n",
        "# Example usage\n",
        "csv_file = \"qm9.csv\"  # Replace with the path to your QM9 CSV file\n",
        "qm9_smiles = load_qm9_smiles(csv_file)\n",
        "\n",
        "print(\"Number of SMILES in QM9 dataset:\", len(qm9_smiles))\n",
        "print(\"Example SMILES:\", qm9_smiles[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "r8NZz6YJLUYG"
      },
      "outputs": [],
      "source": [
        "def remove_hydrogen_from_smiles(smiles_list):\n",
        "    modified_smiles = []\n",
        "    for smiles in smiles_list:\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            print(\"Invalid SMILES:\", smiles)\n",
        "            continue\n",
        "        mol = Chem.RemoveHs(mol)\n",
        "        modified_smiles.append(Chem.MolToSmiles(mol))\n",
        "    return modified_smiles\n",
        "\n",
        "modified_smiles = remove_hydrogen_from_smiles(qm9_smiles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TvoXwHs9LUa4"
      },
      "outputs": [],
      "source": [
        "def smiles_to_graph(smiles):\n",
        "    # Parse the SMILES string\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is None:\n",
        "        return None, None\n",
        "\n",
        "    # Get node features (atomic numbers)\n",
        "    atomic_numbers = [atom.GetAtomicNum() for atom in mol.GetAtoms()]\n",
        "\n",
        "    # Get edge indices (connectivity)\n",
        "    edge_index = []\n",
        "    for bond in mol.GetBonds():\n",
        "        start_idx = bond.GetBeginAtomIdx()\n",
        "        end_idx = bond.GetEndAtomIdx()\n",
        "        edge_index.append([start_idx, end_idx])\n",
        "\n",
        "    # Convert edge indices to PyTorch tensor\n",
        "    edge_index = torch.tensor(edge_index).t().contiguous()\n",
        "\n",
        "    # Convert node features to PyTorch tensor\n",
        "    node_features = torch.tensor(atomic_numbers, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "    return node_features, edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5o0WVU7oLUdp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "filtered_dataset = []\n",
        "\n",
        "# Define encoding mappings\n",
        "encoding_mappings = {\n",
        "    7: [0, 0, 1, 0, 0],\n",
        "    8: [0, 0, 0, 1, 0],\n",
        "    6: [0, 1, 0, 0, 0],\n",
        "    9: [0, 0, 0, 0, 1]\n",
        "}\n",
        "\n",
        "# Iterate over modified SMILES\n",
        "for smile in modified_smiles:\n",
        "    try:\n",
        "        # Convert SMILES to graph representation\n",
        "        node_features, edge_index1 = smiles_to_graph(smile)\n",
        "\n",
        "        # Check if the graph has more than one node\n",
        "        num_nodes = node_features.shape[0]\n",
        "        if num_nodes > 1:\n",
        "            # Convert node features to one-hot encoding\n",
        "            one_hot_encoded = torch.tensor([encoding_mappings[num.item()] for num in node_features], dtype=torch.float32)\n",
        "\n",
        "            # Create Data object and add it to the filtered dataset\n",
        "            graph = Data(x=one_hot_encoded, edge_index=edge_index1, num_nodes=num_nodes)\n",
        "            filtered_dataset.append(graph)\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing SMILES: {smile}. {e}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining the forward heat equation"
      ],
      "metadata": {
        "id": "rTDhA3axoyIf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "ckl95q6Kei6m"
      },
      "outputs": [],
      "source": [
        "\"\"\"Taken from https://github.com/zh217/torch-dct/blob/master/torch_dct/_dct.py\n",
        "Some modifications have been made to work with newer versions of Pytorch\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "def dct(x, norm=None):\n",
        "    \"\"\"\n",
        "    Discrete Cosine Transform, Type II (a.k.a. the DCT)\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param x: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the DCT-II of the signal over the last dimension\n",
        "    \"\"\"\n",
        "    x_shape = x.shape\n",
        "    N = x_shape[-1]\n",
        "    x = x.contiguous().view(-1, N)\n",
        "\n",
        "    v = torch.cat([x[:, ::2], x[:, 1::2].flip([1])], dim=1)\n",
        "\n",
        "    #Vc = torch.fft.rfft(v, 1)\n",
        "    Vc = torch.view_as_real(torch.fft.fft(v, dim=1))\n",
        "\n",
        "    k = - torch.arange(N, dtype=x.dtype,\n",
        "                       device=x.device)[None, :] * np.pi / (2 * N)\n",
        "    W_r = torch.cos(k)\n",
        "    W_i = torch.sin(k)\n",
        "\n",
        "    V = Vc[:, :, 0] * W_r - Vc[:, :, 1] * W_i\n",
        "\n",
        "    if norm == 'ortho':\n",
        "        V[:, 0] /= np.sqrt(N) * 2\n",
        "        V[:, 1:] /= np.sqrt(N / 2) * 2\n",
        "\n",
        "    V = 2 * V.view(*x_shape)\n",
        "\n",
        "    return V\n",
        "\n",
        "\n",
        "def idct(X, norm=None):\n",
        "    \"\"\"\n",
        "    The inverse to DCT-II, which is a scaled Discrete Cosine Transform, Type III\n",
        "    Our definition of idct is that idct(dct(x)) == x\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param X: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the inverse DCT-II of the signal over the last dimension\n",
        "    \"\"\"\n",
        "\n",
        "    x_shape = X.shape\n",
        "    N = x_shape[-1]\n",
        "\n",
        "    X_v = X.contiguous().view(-1, x_shape[-1]) / 2\n",
        "\n",
        "    if norm == 'ortho':\n",
        "        X_v[:, 0] *= np.sqrt(N) * 2\n",
        "        X_v[:, 1:] *= np.sqrt(N / 2) * 2\n",
        "\n",
        "    k = torch.arange(x_shape[-1], dtype=X.dtype,\n",
        "                     device=X.device)[None, :] * np.pi / (2 * N)\n",
        "    W_r = torch.cos(k)\n",
        "    W_i = torch.sin(k)\n",
        "\n",
        "    V_t_r = X_v\n",
        "    V_t_i = torch.cat([X_v[:, :1] * 0, -X_v.flip([1])[:, :-1]], dim=1)\n",
        "\n",
        "    V_r = V_t_r * W_r - V_t_i * W_i\n",
        "    V_i = V_t_r * W_i + V_t_i * W_r\n",
        "\n",
        "    V = torch.cat([V_r.unsqueeze(2), V_i.unsqueeze(2)], dim=2)\n",
        "\n",
        "    #v = torch.fft.irfft(V, 1)\n",
        "    v = torch.fft.irfft(torch.view_as_complex(V), n=V.shape[1], dim=1)\n",
        "    x = v.new_zeros(v.shape)\n",
        "    x[:, ::2] += v[:, :N - (N // 2)]\n",
        "    x[:, 1::2] += v.flip([1])[:, :N // 2]\n",
        "\n",
        "    return x.view(*x_shape)\n",
        "\n",
        "\n",
        "def dct_2d(x, norm=None):\n",
        "    \"\"\"\n",
        "    2-dimentional Discrete Cosine Transform, Type II (a.k.a. the DCT)\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param x: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the DCT-II of the signal over the last 2 dimensions\n",
        "    \"\"\"\n",
        "    X1 = dct(x, norm=norm)\n",
        "    X2 = dct(X1.transpose(-1, -2), norm=norm)\n",
        "    return X2.transpose(-1, -2)\n",
        "\n",
        "\n",
        "def idct_2d(X, norm=None):\n",
        "    \"\"\"\n",
        "    The inverse to 2D DCT-II, which is a scaled Discrete Cosine Transform, Type III\n",
        "    Our definition of idct is that idct_2d(dct_2d(x)) == x\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param X: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the DCT-II of the signal over the last 2 dimensions\n",
        "    \"\"\"\n",
        "    x1 = idct(X, norm=norm)\n",
        "    x2 = idct(x1.transpose(-1, -2), norm=norm)\n",
        "    return x2.transpose(-1, -2)\n",
        "\n",
        "\n",
        "def dct_3d(x, norm=None):\n",
        "    \"\"\"\n",
        "    3-dimentional Discrete Cosine Transform, Type II (a.k.a. the DCT)\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param x: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the DCT-II of the signal over the last 3 dimensions\n",
        "    \"\"\"\n",
        "    X1 = dct(x, norm=norm)\n",
        "    X2 = dct(X1.transpose(-1, -2), norm=norm)\n",
        "    X3 = dct(X2.transpose(-1, -3), norm=norm)\n",
        "    return X3.transpose(-1, -3).transpose(-1, -2)\n",
        "\n",
        "\n",
        "def idct_3d(X, norm=None):\n",
        "    \"\"\"\n",
        "    The inverse to 3D DCT-II, which is a scaled Discrete Cosine Transform, Type III\n",
        "    Our definition of idct is that idct_3d(dct_3d(x)) == x\n",
        "    For the meaning of the parameter `norm`, see:\n",
        "    https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.fftpack.dct.html\n",
        "    :param X: the input signal\n",
        "    :param norm: the normalization, None or 'ortho'\n",
        "    :return: the DCT-II of the signal over the last 3 dimensions\n",
        "    \"\"\"\n",
        "    x1 = idct(X, norm=norm)\n",
        "    x2 = idct(x1.transpose(-1, -2), norm=norm)\n",
        "    x3 = idct(x2.transpose(-1, -3), norm=norm)\n",
        "    return x3.transpose(-1, -3).transpose(-1, -2)\n",
        "\n",
        "class DCTBlur1D(nn.Module):\n",
        "\n",
        "    def __init__(self, blur_sigmas, device):\n",
        "        super().__init__()\n",
        "        self.blur_sigmas = torch.tensor(blur_sigmas).to(device)\n",
        "\n",
        "\n",
        "    def forward(self, x,img, fwd_steps):\n",
        "        freqs = np.pi*torch.linspace(0, img-1, img)/img\n",
        "        frequencies_squared = freqs[None, :]**2\n",
        "        if len(x.shape) == 4:\n",
        "            sigmas = self.blur_sigmas[fwd_steps][:, None, None, None]\n",
        "        elif len(x.shape) == 3:\n",
        "            sigmas = self.blur_sigmas[fwd_steps][:, None, None]\n",
        "        elif len(x.shape) == 2:\n",
        "            sigmas = self.blur_sigmas[fwd_steps][:, None]\n",
        "        t = sigmas**2/2\n",
        "        dct_coefs = dct(x, norm='ortho')\n",
        "        dct_coefs = dct_coefs * torch.exp(- frequencies_squared * t)\n",
        "        return idct(dct_coefs, norm='ortho')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GNN model helpers"
      ],
      "metadata": {
        "id": "SM6VhukGo8Gx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yI0tzhjunRhY"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "import math\n",
        "\n",
        "def unsorted_segment_sum(data, segment_ids, num_segments, normalization_factor, aggregation_method: str):\n",
        "    \"\"\"Custom PyTorch op to replicate TensorFlow's `unsorted_segment_sum`.\n",
        "        Normalization: 'sum' or 'mean'.\n",
        "    \"\"\"\n",
        "    result_shape = (num_segments, data.size(1))\n",
        "    result = data.new_full(result_shape, 0)  # Init empty result tensor.\n",
        "    segment_ids = segment_ids.unsqueeze(-1).expand(-1, data.size(1))\n",
        "    result.scatter_add_(0, segment_ids, data)\n",
        "    if aggregation_method == 'sum':\n",
        "        result = result / normalization_factor\n",
        "\n",
        "    if aggregation_method == 'mean':\n",
        "        norm = data.new_zeros(result.shape)\n",
        "        norm.scatter_add_(0, segment_ids, data.new_ones(data.shape))\n",
        "        norm[norm == 0] = 1\n",
        "        result = result / norm\n",
        "    return result\n",
        "\n",
        "class GCL(nn.Module):\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=0, nodes_att_dim=0, act_fn=nn.SiLU(), attention=False):\n",
        "        super(GCL, self).__init__()\n",
        "        input_edge = input_nf * 2\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "        self.attention = attention\n",
        "\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge + edges_in_d, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn)\n",
        "\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_nf + input_nf + nodes_att_dim, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, output_nf))\n",
        "\n",
        "        if self.attention:\n",
        "            self.att_mlp = nn.Sequential(\n",
        "                nn.Linear(hidden_nf, 1),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "    def edge_model(self, source, target, edge_attr, edge_mask):\n",
        "        if edge_attr is None:  # Unused.\n",
        "            out = torch.cat([source, target], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([source, target, edge_attr], dim=1)\n",
        "\n",
        "        mij = self.edge_mlp(out)\n",
        "\n",
        "        if self.attention:\n",
        "            att_val = self.att_mlp(mij)\n",
        "            out = mij * att_val\n",
        "        else:\n",
        "            out = mij\n",
        "\n",
        "        if edge_mask is not None:\n",
        "            out = out * edge_mask\n",
        "        return out, mij\n",
        "\n",
        "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        if node_attr is not None:\n",
        "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
        "        else:\n",
        "            agg = torch.cat([x, agg], dim=1)\n",
        "        out = x + self.node_mlp(agg)\n",
        "        return out, agg\n",
        "\n",
        "    def forward(self, h, edge_index, edge_attr=None, node_attr=None, node_mask=None, edge_mask=None):\n",
        "        row, col = edge_index\n",
        "        edge_feat, mij = self.edge_model(h[row], h[col], edge_attr, edge_mask)\n",
        "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, mij\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FrefYnLInIDD"
      },
      "outputs": [],
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, in_node_nf, in_edge_nf, hidden_nf, out_node_nf,aggregation_method='sum', device='cpu',\n",
        "                 act_fn=nn.SiLU(), n_layers=4, attention=False,\n",
        "                 normalization_factor=100, ):\n",
        "        super(GNN, self).__init__()\n",
        "        if out_node_nf is None:\n",
        "            out_node_nf = in_node_nf\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        ### Encoder\n",
        "        self.embedding = nn.Linear(in_node_nf, self.hidden_nf)\n",
        "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"gcl_%d\" % i, GCL(\n",
        "                self.hidden_nf, self.hidden_nf, self.hidden_nf,\n",
        "                normalization_factor=normalization_factor,\n",
        "                aggregation_method=aggregation_method,\n",
        "                edges_in_d=in_edge_nf, act_fn=act_fn,\n",
        "                attention=attention))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, edges, edge_attr=None, node_mask=None, edge_mask=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        h = self.embedding(h)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](h, edges, edge_attr=edge_attr, node_mask=node_mask, edge_mask=edge_mask)\n",
        "        h = self.embedding_out(h)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-idZPoZF7rPK"
      },
      "outputs": [],
      "source": [
        "\n",
        "def coord2diff(x, edge_index, norm_constant=1):\n",
        "    row, col = edge_index\n",
        "    coord_diff = x[row] - x[col]\n",
        "    radial = torch.sum((coord_diff) ** 2, 1).unsqueeze(1)\n",
        "    norm = torch.sqrt(radial + 1e-8)\n",
        "    coord_diff = coord_diff/(norm + norm_constant)\n",
        "    return radial, coord_diff\n",
        "class GCL(nn.Module):\n",
        "    def __init__(self, input_nf, output_nf, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=0, nodes_att_dim=0, act_fn=nn.SiLU(), attention=False):\n",
        "        super(GCL, self).__init__()\n",
        "        input_edge = input_nf * 2\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "        self.attention = attention\n",
        "\n",
        "        self.edge_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge + edges_in_d, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn)\n",
        "\n",
        "        self.node_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_nf + input_nf + nodes_att_dim, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, output_nf))\n",
        "\n",
        "        if self.attention:\n",
        "            self.att_mlp = nn.Sequential(\n",
        "                nn.Linear(hidden_nf, 1),\n",
        "                nn.Sigmoid())\n",
        "\n",
        "    def edge_model(self, source, target, edge_attr, edge_mask):\n",
        "        if edge_attr is None:  # Unused.\n",
        "            out = torch.cat([source, target], dim=1)\n",
        "        else:\n",
        "            out = torch.cat([source, target, edge_attr], dim=1)\n",
        "        mij = self.edge_mlp(out)\n",
        "\n",
        "        if self.attention:\n",
        "            att_val = self.att_mlp(mij)\n",
        "            out = mij * att_val\n",
        "        else:\n",
        "            out = mij\n",
        "\n",
        "        if edge_mask is not None:\n",
        "            out = out * edge_mask\n",
        "        return out, mij\n",
        "\n",
        "    def node_model(self, x, edge_index, edge_attr, node_attr):\n",
        "        row, col = edge_index\n",
        "        agg = unsorted_segment_sum(edge_attr, row, num_segments=x.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        if node_attr is not None:\n",
        "            agg = torch.cat([x, agg, node_attr], dim=1)\n",
        "        else:\n",
        "            agg = torch.cat([x, agg], dim=1)\n",
        "        out = x + self.node_mlp(agg)\n",
        "        return out, agg\n",
        "\n",
        "    def forward(self, h, edge_index, edge_attr=None, node_attr=None, node_mask=None, edge_mask=None):\n",
        "        row, col = edge_index\n",
        "        edge_feat, mij = self.edge_model(h[row], h[col], edge_attr, edge_mask)\n",
        "        h, agg = self.node_model(h, edge_index, edge_feat, node_attr)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, mij\n",
        "\n",
        "\n",
        "class EquivariantUpdate(nn.Module):\n",
        "    def __init__(self, hidden_nf, normalization_factor, aggregation_method,\n",
        "                 edges_in_d=1, act_fn=nn.SiLU(), tanh=False, coords_range=10.0):\n",
        "        super(EquivariantUpdate, self).__init__()\n",
        "        self.tanh = tanh\n",
        "        self.coords_range = coords_range\n",
        "        input_edge = hidden_nf * 2 + edges_in_d\n",
        "        layer = nn.Linear(hidden_nf, 1, bias=False)\n",
        "        torch.nn.init.xavier_uniform_(layer.weight, gain=0.001)\n",
        "        self.coord_mlp = nn.Sequential(\n",
        "            nn.Linear(input_edge, hidden_nf),\n",
        "            act_fn,\n",
        "            nn.Linear(hidden_nf, hidden_nf),\n",
        "            act_fn,\n",
        "            layer)\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "    def coord_model(self, h, coord, edge_index, coord_diff, edge_attr, edge_mask):\n",
        "        row, col = edge_index\n",
        "        input_tensor = torch.cat([h[row], h[col], edge_attr], dim=1)\n",
        "        if self.tanh:\n",
        "            trans = coord_diff * torch.tanh(self.coord_mlp(input_tensor)) * self.coords_range\n",
        "        else:\n",
        "            trans = coord_diff * self.coord_mlp(input_tensor)\n",
        "        if edge_mask is not None:\n",
        "            trans = trans * edge_mask\n",
        "        agg = unsorted_segment_sum(trans, row, num_segments=coord.size(0),\n",
        "                                   normalization_factor=self.normalization_factor,\n",
        "                                   aggregation_method=self.aggregation_method)\n",
        "        coord = coord + agg\n",
        "        return coord\n",
        "\n",
        "    def forward(self, h, coord, edge_index, coord_diff, edge_attr=None, node_mask=None, edge_mask=None):\n",
        "        coord = self.coord_model(h, coord, edge_index, coord_diff, edge_attr, edge_mask)\n",
        "        if node_mask is not None:\n",
        "            coord = coord * node_mask\n",
        "        return coord\n",
        "\n",
        "\n",
        "class EquivariantBlock(nn.Module):\n",
        "    def __init__(self, hidden_nf, edge_feat_nf=2, device='cpu', act_fn=nn.SiLU(), n_layers=2, attention=True,\n",
        "                 norm_diff=True, tanh=False, coords_range=15, norm_constant=1, sin_embedding=None,\n",
        "                 normalization_factor=100, aggregation_method='sum'):\n",
        "        super(EquivariantBlock, self).__init__()\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        self.coords_range_layer = float(coords_range)\n",
        "        self.norm_diff = norm_diff\n",
        "        self.norm_constant = norm_constant\n",
        "        self.sin_embedding = sin_embedding\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"gcl_%d\" % i, GCL(self.hidden_nf, self.hidden_nf, self.hidden_nf, edges_in_d=edge_feat_nf,\n",
        "                                              act_fn=act_fn, attention=attention,\n",
        "                                              normalization_factor=self.normalization_factor,\n",
        "                                              aggregation_method=self.aggregation_method))\n",
        "        self.add_module(\"gcl_equiv\", EquivariantUpdate(hidden_nf, edges_in_d=edge_feat_nf, act_fn=nn.SiLU(), tanh=tanh,\n",
        "                                                       coords_range=self.coords_range_layer,\n",
        "                                                       normalization_factor=self.normalization_factor,\n",
        "                                                       aggregation_method=self.aggregation_method))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, x, edge_index, node_mask=None, edge_mask=None, edge_attr=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        distances, coord_diff = coord2diff(x, edge_index, self.norm_constant)\n",
        "        if self.sin_embedding is not None:\n",
        "            distances = self.sin_embedding(distances)\n",
        "        edge_attr = torch.cat([distances, edge_attr], dim=1)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, _ = self._modules[\"gcl_%d\" % i](h, edge_index, edge_attr=edge_attr, node_mask=node_mask, edge_mask=edge_mask)\n",
        "        x = self._modules[\"gcl_equiv\"](h, x, edge_index, coord_diff, edge_attr, node_mask, edge_mask)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, x\n",
        "\n",
        "\n",
        "class EGNN(nn.Module):\n",
        "    def __init__(self, in_node_nf, in_edge_nf, hidden_nf, device='cpu', act_fn=nn.SiLU(), n_layers=3, attention=False,\n",
        "                 norm_diff=True, out_node_nf=None, tanh=False, coords_range=15, norm_constant=1, inv_sublayers=2,\n",
        "                 sin_embedding=False, normalization_factor=100, aggregation_method='sum'):\n",
        "        super(EGNN, self).__init__()\n",
        "        if out_node_nf is None:\n",
        "            out_node_nf = in_node_nf\n",
        "        self.hidden_nf = hidden_nf\n",
        "        self.device = device\n",
        "        self.n_layers = n_layers\n",
        "        self.coords_range_layer = float(coords_range/n_layers) if n_layers > 0 else float(coords_range)\n",
        "        self.norm_diff = norm_diff\n",
        "        self.normalization_factor = normalization_factor\n",
        "        self.aggregation_method = aggregation_method\n",
        "\n",
        "        if sin_embedding:\n",
        "            self.sin_embedding = SinusoidsEmbeddingNew()\n",
        "            edge_feat_nf = self.sin_embedding.dim * 2\n",
        "        else:\n",
        "            self.sin_embedding = None\n",
        "            edge_feat_nf = 2\n",
        "\n",
        "        self.embedding = nn.Linear(in_node_nf, self.hidden_nf)\n",
        "        self.embedding_out = nn.Linear(self.hidden_nf, out_node_nf)\n",
        "        for i in range(0, n_layers):\n",
        "            self.add_module(\"e_block_%d\" % i, EquivariantBlock(hidden_nf, edge_feat_nf=edge_feat_nf, device=device,\n",
        "                                                               act_fn=act_fn, n_layers=inv_sublayers,\n",
        "                                                               attention=attention, norm_diff=norm_diff, tanh=tanh,\n",
        "                                                               coords_range=coords_range, norm_constant=norm_constant,\n",
        "                                                               sin_embedding=self.sin_embedding,\n",
        "                                                               normalization_factor=self.normalization_factor,\n",
        "                                                               aggregation_method=self.aggregation_method))\n",
        "        self.to(self.device)\n",
        "\n",
        "    def forward(self, h, x, edge_index, node_mask=None, edge_mask=None):\n",
        "        # Edit Emiel: Remove velocity as input\n",
        "        distances, _ = coord2diff(x, edge_index)\n",
        "        if self.sin_embedding is not None:\n",
        "            distances = self.sin_embedding(distances)\n",
        "        h = self.embedding(h)\n",
        "        for i in range(0, self.n_layers):\n",
        "            h, x = self._modules[\"e_block_%d\" % i](h, x, edge_index, node_mask=node_mask, edge_mask=edge_mask, edge_attr=distances)\n",
        "\n",
        "        # Important, the bias of the last linear might be non-zero\n",
        "        h = self.embedding_out(h)\n",
        "        if node_mask is not None:\n",
        "            h = h * node_mask\n",
        "        return h, x\n",
        "\n",
        "def fully_connected_graph_with_self_loops(num_nodes):\n",
        "    \"\"\"\n",
        "    Generates edge indices for a fully connected graph with self-loops.\n",
        "\n",
        "    Args:\n",
        "        num_nodes (int): Number of nodes in the graph.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Edge indices of the fully connected graph with self-loops.\n",
        "    \"\"\"\n",
        "    # Create edge indices for a fully connected graph with self-loops\n",
        "    edge_index = torch.tensor([[i, j] for i in range(num_nodes) for j in range(num_nodes)])\n",
        "\n",
        "    return edge_index.t().contiguous()\n",
        "\n",
        "\n",
        "def edge_index_to_adj(edge_index, num_nodes):\n",
        "    # Create an empty adjacency matrix\n",
        "    adj = torch.zeros(num_nodes, num_nodes)\n",
        "\n",
        "    # Fill the adjacency matrix using the edge indices\n",
        "    adj[edge_index[0], edge_index[1]] = 1\n",
        "    adj[edge_index[1], edge_index[0]] = 1  # For undirected graphs, if edge (i,j) exists, edge (j,i) also exists\n",
        "\n",
        "    return adj\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoder model\n"
      ],
      "metadata": {
        "id": "YAn0X3OOpBX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "from torch.nn import Linear\n",
        "from torch_geometric.nn import PNAConv\n",
        "\n",
        "class GraphAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GraphAutoencoder, self).__init__()\n",
        "\n",
        "        # Define the parameters for the autoencoder\n",
        "\n",
        "        in_edge_nf = 0  # Replace with the actual input edge feature dimension\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        act_fn = torch.nn.SiLU()\n",
        "        n_layers = 4  # Replace with the desired number of layers\n",
        "\n",
        "        # Define the encoder and decoder parts\n",
        "        self.conv1 = GNN(\n",
        "            in_node_nf=5,\n",
        "            in_edge_nf=in_edge_nf,\n",
        "            hidden_nf=8,\n",
        "            out_node_nf=3,\n",
        "            device=device,\n",
        "            act_fn=act_fn,\n",
        "            n_layers=n_layers\n",
        "        )\n",
        "\n",
        "\n",
        "        self.conv2 = GNN(\n",
        "            in_node_nf=3,\n",
        "            in_edge_nf=in_edge_nf,\n",
        "            hidden_nf=5,\n",
        "            out_node_nf=1,\n",
        "            device=device,\n",
        "            act_fn=act_fn,\n",
        "            n_layers=n_layers\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.dconv1 = GNN(\n",
        "            in_node_nf=1,\n",
        "            in_edge_nf=in_edge_nf,\n",
        "            hidden_nf=5,\n",
        "            out_node_nf=3,\n",
        "            device=device,\n",
        "            act_fn=act_fn,\n",
        "            n_layers=n_layers\n",
        "        )\n",
        "\n",
        "\n",
        "        self.dconv2 = GNN(\n",
        "            in_node_nf=3,\n",
        "            in_edge_nf=in_edge_nf,\n",
        "            hidden_nf=8,\n",
        "            out_node_nf=5,\n",
        "            device=device,\n",
        "            act_fn=act_fn,\n",
        "            n_layers=n_layers\n",
        "        )\n",
        "\n",
        "\n",
        "        self.edge_classifier = nn.Sequential(\n",
        "            nn.Linear(10, 32),  # Adjust the input and hidden layers as needed\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1),\n",
        "            nn.Sigmoid()  # Output probability between 0 and 1\n",
        "        )\n",
        "\n",
        "\n",
        "        # Define the edge classifier MLP\n",
        "\n",
        "\n",
        "    def encode(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "    def decode(self, z, edge_index):\n",
        "        z = self.dconv1(z, edge_index)\n",
        "        z = self.dconv2(z, edge_index)\n",
        "        return z\n",
        "\n",
        "    def edge_prediction(self, recon, num_rows2):\n",
        "         edge=torch.empty(0)\n",
        "         for i in range(num_rows2):\n",
        "            for j in range(i + 1, num_rows2):  # Start from i+1 to avoid duplicate pairs\n",
        "                # Select the pair of rows from recon tensor\n",
        "                pair_features = recon[[i, j], :]\n",
        "\n",
        "                # Concatenate the pair features along dimension 1\n",
        "                con_tensor = torch.cat([pair_features[0], pair_features[1]], dim=0)\n",
        "\n",
        "\n",
        "                # Call edge_prediction method for the pair of rows\n",
        "                edge_prob = self.edge_classifier(con_tensor)\n",
        "                edge= torch.cat((edge, edge_prob), dim=0)\n",
        "         return edge\n",
        "\n",
        "# Define other necessary components and hyperparameters\n",
        "epochs = 50\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model= GraphAutoencoder()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
        "criterion = nn.MSELoss()"
      ],
      "metadata": {
        "id": "S6KjfoxuJhWJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training the latent space autoencoder"
      ],
      "metadata": {
        "id": "uI-aTAbopFrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1=filtered_dataset[:1000]\n",
        "for epoch in range(10):\n",
        "\n",
        "    total_loss = 0\n",
        "\n",
        "    print(epoch)\n",
        "    for data in data1:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        edge_index_1 = data.edge_index.to(device)\n",
        "\n",
        "        node_features_1 = data.x.to(device)[:,:5]\n",
        "\n",
        "\n",
        "        num_nodes_1 = node_features_1.size(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        adjacency_matrix_1 = edge_index_to_adj(edge_index_1, num_nodes_1)\n",
        "\n",
        "        num_vectors_1 = node_features_1.size(0)\n",
        "        num_upper_triangle_terms_1 = int((num_vectors_1 * (num_vectors_1 - 1)) / 2)\n",
        "\n",
        "        pairwise_distances_1 = torch.zeros(num_upper_triangle_terms_1)\n",
        "\n",
        "        k= 0\n",
        "\n",
        "        for i in range(num_vectors_1):\n",
        "            for j in range(i + 1, num_vectors_1):\n",
        "\n",
        "\n",
        "                pairwise_distances_1[k] = adjacency_matrix_1[i][j]\n",
        "\n",
        "                k=k+ 1\n",
        "\n",
        "\n",
        "\n",
        "        pairwise_distances_1 = pairwise_distances_1.view(-1, 1)\n",
        "        pairwise_distances_1= torch.where(pairwise_distances_1 == 0, 0, pairwise_distances_1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        column_tensor_1 = pairwise_distances_1\n",
        "\n",
        "\n",
        "        num_repeats_1 =5\n",
        "\n",
        "\n",
        "        row_tensor_1 = column_tensor_1.repeat(1, num_repeats_1).to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        updated_node_features_1 = torch.cat([node_features_1, row_tensor_1], dim=0)\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        z =model.encode(node_features_1,edge_index_1.to(device)) #encode\n",
        "        z= torch.exp(z)\n",
        "        edge_index1 = fully_connected_graph_with_self_loops(num_nodes_1).to(device)\n",
        "\n",
        "\n",
        "        recon = model.decode(z.to(device), edge_index1.to(device))\n",
        "\n",
        "        num_rows2 = recon.size(0)\n",
        "\n",
        "\n",
        "        edge= model.edge_prediction(recon, num_rows2).unsqueeze(1)\n",
        "\n",
        "\n",
        "        loss = criterion(edge,column_tensor_1)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "\n",
        "    average_loss = total_loss / len(data1)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {average_loss:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LWVH-SVKg-sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save and load the model"
      ],
      "metadata": {
        "id": "q-7HaLxKpKJk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = f\"autoencoder.pickle\"\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "qOSgvCrch4n4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import path\n",
        "import pickle\n",
        "\n",
        "path=  'autoencoder.pickle'\n",
        "with open(path, 'rb') as file:\n",
        "      loaded_auto = pickle.load(file)"
      ],
      "metadata": {
        "id": "d3p-fgJiiBGE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reverse Heat model\n"
      ],
      "metadata": {
        "id": "820KN1ySpTud"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ogfNn-k3nIFw"
      },
      "outputs": [],
      "source": [
        "torch.set_default_dtype(torch.float32)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.utils import add_self_loops\n",
        "\n",
        "in_node_nf = 1\n",
        "out_node_nf = 1\n",
        "in_edge_nf = 0\n",
        "hidden_nf = 4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "act_fn = torch.nn.SiLU()\n",
        "n_layers = 4\n",
        "\n",
        "\n",
        "\n",
        "# Instantiate the GNN model\n",
        "model = GNN(\n",
        "    in_node_nf=in_node_nf,\n",
        "    in_edge_nf=in_edge_nf,\n",
        "    hidden_nf=hidden_nf,\n",
        "    out_node_nf= out_node_nf,\n",
        "    device=device,\n",
        "    act_fn=act_fn,\n",
        "    n_layers=n_layers\n",
        ")\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcPzAWCFnIJA"
      },
      "outputs": [],
      "source": [
        "!pip install einops\n",
        "import os\n",
        "from os.path import join as pjoin\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from einops import repeat, rearrange\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import HTML, Image\n",
        "from matplotlib.animation import FuncAnimation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Blur Parameters"
      ],
      "metadata": {
        "id": "HecZYcYBpXsd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "blur_sigma_max =1\n",
        "\n",
        "blur_sigma_min = 0.2\n",
        "blur_schedule = np.exp(np.linspace(np.log(blur_sigma_min), np.log(blur_sigma_max),100))\n",
        "\n",
        "device='cpu'\n",
        "blur_schedule"
      ],
      "metadata": {
        "id": "4Nw_X82yKkYO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b88067-b4eb-40ac-db60-da76cd719205"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.2       , 0.20327796, 0.20660965, 0.20999594, 0.21343774,\n",
              "       0.21693594, 0.22049148, 0.22410529, 0.22777834, 0.23151158,\n",
              "       0.23530601, 0.23916263, 0.24308247, 0.24706654, 0.25111592,\n",
              "       0.25523166, 0.25941486, 0.26366662, 0.26798806, 0.27238034,\n",
              "       0.2768446 , 0.28138203, 0.28599383, 0.29068121, 0.29544543,\n",
              "       0.30028772, 0.30520938, 0.3102117 , 0.31529601, 0.32046366,\n",
              "       0.325716  , 0.33105442, 0.33648034, 0.34199519, 0.34760043,\n",
              "       0.35329753, 0.35908801, 0.3649734 , 0.37095524, 0.37703513,\n",
              "       0.38321466, 0.38949548, 0.39587924, 0.40236762, 0.40896235,\n",
              "       0.41566517, 0.42247784, 0.42940218, 0.43644   , 0.44359317,\n",
              "       0.45086357, 0.45825314, 0.46576383, 0.47339761, 0.48115651,\n",
              "       0.48904257, 0.49705789, 0.50520457, 0.51348478, 0.5219007 ,\n",
              "       0.53045455, 0.5391486 , 0.54798515, 0.55696652, 0.5660951 ,\n",
              "       0.57537329, 0.58480355, 0.59438837, 0.60413028, 0.61403186,\n",
              "       0.62409573, 0.63432454, 0.644721  , 0.65528786, 0.6660279 ,\n",
              "       0.67694397, 0.68803896, 0.69931579, 0.71077744, 0.72242695,\n",
              "       0.73426739, 0.7463019 , 0.75853364, 0.77096587, 0.78360185,\n",
              "       0.79644494, 0.80949852, 0.82276605, 0.83625103, 0.84995703,\n",
              "       0.86388766, 0.87804662, 0.89243764, 0.90706452, 0.92193114,\n",
              "       0.93704142, 0.95239935, 0.968009  , 0.98387448, 1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mod = DCTBlur1D(blur_schedule, device)"
      ],
      "metadata": {
        "id": "Df4D_073Kmoz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training\n"
      ],
      "metadata": {
        "id": "KxhfiGtopcvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "epochs =10\n",
        "data1= filtered_dataset[:1000]\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "\n",
        "    print(epoch)\n",
        "\n",
        "    for data in data1:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        random_integer = random.randint(1, 98)\n",
        "        num_nodes=data.x.size(0)\n",
        "        x=loaded_auto.encode(data.x,data.edge_index)\n",
        "        x= torch.exp(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        dat = torch.squeeze(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        fwd_steps = torch.linspace(1, 99,99, dtype=torch.long, device=device)\n",
        "\n",
        "        blurred_batch =  mod(repeat(dat, 'd -> N d', N=99),num_nodes,fwd_steps).float()\n",
        "        blurred= blurred_batch[random_integer]\n",
        "\n",
        "        less_blurred= blurred_batch[random_integer-1]\n",
        "        sigma=0.01\n",
        "        noise = torch.randn_like(blurred) * sigma\n",
        "        perturbed_data = noise + blurred\n",
        "        pert =perturbed_data .unsqueeze(1)\n",
        "        edge_index = data.edge_index\n",
        "        h=pert[:,:1]\n",
        "        h1= torch.ones_like(h)\n",
        "        h_time = torch.empty_like(h1[:, 0:1]).fill_(random_integer)\n",
        "        edge_index1 = fully_connected_graph_with_self_loops(num_nodes).to(device)\n",
        "\n",
        "        output = model(pert, edge_index1)\n",
        "\n",
        "\n",
        "        diff= torch.squeeze(output)\n",
        "        prediction = perturbed_data + diff\n",
        "\n",
        "        loss = F.mse_loss(less_blurred,prediction)*100\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    average_loss = total_loss /len(data1)\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {average_loss:.4f}\")"
      ],
      "metadata": {
        "id": "C8P44L_qKpdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "filename = f\"reverse_heat.pickle\"\n",
        "with open(filename, 'wb') as f:\n",
        "    pickle.dump(model, f)"
      ],
      "metadata": {
        "id": "OQHvqChUlv2Z"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sys import path\n",
        "import pickle\n",
        "\n",
        "path=  'reverse_heat.pickle'\n",
        "with open(path, 'rb') as file:\n",
        "      loaded_heat = pickle.load(file)"
      ],
      "metadata": {
        "id": "JnRXBUi0l_Xh"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generation"
      ],
      "metadata": {
        "id": "QWx8Of67pfXX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "deblur=[]\n",
        "data= filtered_dataset[901]\n",
        "num_nodes= data.x.size(0)\n",
        "K=90\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "x = loaded_auto.encode(data.x,data.edge_index)\n",
        "x= torch.exp(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dat = torch.squeeze(x)\n",
        "\n",
        "\n",
        "\n",
        "fwd_steps = torch.linspace(1, 99,99, dtype=torch.long, device=device)\n",
        "intial_batch =  mod(repeat(dat, 'd -> N d', N=99),num_nodes,fwd_steps).float()\n",
        "initial_sample= intial_batch[90]\n",
        "noises = [torch.randn_like(initial_sample[0], dtype=torch.float)[None] for i in range(K)]\n",
        "intermediate_samples_out = []\n",
        "u = initial_sample.to(device).float()\n",
        "intermediate_samples_out = []\n",
        "\n",
        "\n",
        "for i in range(K, 0, -1):\n",
        "\n",
        "     edge_index = fully_connected_graph_with_self_loops(num_nodes)\n",
        "     pert =u .unsqueeze(1)\n",
        "\n",
        "\n",
        "     output = loaded_heat(pert, edge_index)\n",
        "     u_mean= torch.squeeze(output)+u\n",
        "     noise = noises[i-1]\n",
        "     u = u_mean + noise*0.0125\n",
        "\n",
        "     deblur.append(u)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1OFypcnqKpgH"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The generated latent space is stored in deblur which can be decoded using the autoencoder"
      ],
      "metadata": {
        "id": "ZW5dxdf_pizN"
      }
    }
  ]
}